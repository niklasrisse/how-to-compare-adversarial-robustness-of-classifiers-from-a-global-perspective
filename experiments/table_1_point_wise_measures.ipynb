{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Point-wise measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"../\")\n",
    "import sys\n",
    "import json\n",
    "from argparse import Namespace\n",
    "import numpy as np\n",
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import foolbox\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances as dist\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set(context='paper')\n",
    "\n",
    "import provable_robustness_max_linear_regions.data as dt\n",
    "from provable_robustness_max_linear_regions import models\n",
    "from provable_robustness_max_linear_regions.models import load_model\n",
    "from robustness_curves import generate_curve_data\n",
    "from utils import NumpyEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate robustness curves:\n",
    "Estimated runtime (if no file with data is present): 2 days"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_from_json(file_name):\n",
    "\n",
    "    if not os.path.exists(\"res/\" + file_name + \".json\"):\n",
    "        return None\n",
    "    else:\n",
    "        with open(\"res/\" + file_name + \".json\", 'r') as fp:\n",
    "            loaded_json =  json.load(fp)\n",
    "\n",
    "            for key in loaded_json.keys():\n",
    "                loaded_json[key][\"x\"] = np.array(loaded_json[key][\"x\"])\n",
    "                loaded_json[key][\"y\"] = np.array(loaded_json[key][\"y\"])\n",
    "\n",
    "                loaded_json[key][\"y\"][np.isnan(loaded_json[key][\"x\"])] = 1.0\n",
    "                loaded_json[key][\"x\"] = np.nan_to_num(loaded_json[key][\"x\"], nan = np.nanmax(loaded_json[key][\"x\"]))\n",
    "\n",
    "            return loaded_json\n",
    "        \n",
    "def save_to_json(dictionary, file_name):\n",
    "        \n",
    "    if not os.path.exists(\"res\"):\n",
    "        os.makedirs(\"res\")\n",
    "\n",
    "    with open(\"res/\" + file_name + \".json\", 'w') as fp:\n",
    "        json.dump(dictionary, fp, cls = NumpyEncoder)\n",
    "\n",
    "\n",
    "training_method_to_model_path = {\"ST\": \"provable_robustness_max_linear_regions/models/plain/2019-02-19 01_20_16 dataset=cifar10 nn_type=cnn_lenet_small p_norm=inf lmbd=0.0 gamma_rb=0.0 gamma_db=0.0 ae_frac=0.0 epoch=100.mat\",\n",
    "                                    \"MMR+AT_l_inf\": \"provable_robustness_max_linear_regions/models/mmr+at/2019-02-17 23_20_04 dataset=cifar10 nn_type=cnn_lenet_small p_norm=inf lmbd=0.1 gamma_rb=3.0 gamma_db=3.0 ae_frac=0.5 epoch=100.mat\", \n",
    "                                    \"MMR+AT_l_2\": \"provable_robustness_max_linear_regions/models/mmr+at/2019-02-24 10_56_36 dataset=cifar10 nn_type=cnn_lenet_small p_norm=2 lmbd=0.5 gamma_rb=0.15 gamma_db=0.15 ae_frac=0.5 lr=0.001 epoch=100.mat\", \n",
    "                                    \"KW_l_inf\": \"provable_robustness_max_linear_regions/models/kw/p_norm=inf dataset=cifar10_model=cnn_lenet_small_method=robust_eps=0.007843_checkpoint.mat\", \n",
    "                                    \"KW_l_2\": \"provable_robustness_max_linear_regions/models/kw/p_norm=2 dataset=cifar10_model=cnn_lenet_small_method=robust_eps=0.1_checkpoint.mat\", \n",
    "                                    \"AT_l_inf\": \"provable_robustness_max_linear_regions/models/at/2019-02-19 01_20_16 dataset=cifar10 nn_type=cnn_lenet_small p_norm=inf lmbd=0.0 gamma_rb=0.0 gamma_db=0.0 ae_frac=0.5 epoch=100.mat\", \n",
    "                                    \"AT_l_2\": \"provable_robustness_max_linear_regions/models/at/2019-02-22 02_40_47 dataset=cifar10 nn_type=cnn_lenet_small p_norm=2 lmbd=0.0 gamma_rb=0.0 gamma_db=0.0 ae_frac=0.5 epoch=100.mat\",\n",
    "                                    \"MMRUNIV\": \"experiments/additional_models/mmr_univ_cifar10_gammas_6.0_6.0_lmabdas_1.0_6.0.mat\"}\n",
    "\n",
    "n_points = 10000\n",
    "\n",
    "_, x_test, _, y_test = dt.get_dataset(\"cifar10\")\n",
    "\n",
    "x_test = x_test[:n_points]\n",
    "y_test = y_test[:n_points]\n",
    "\n",
    "x_test = x_test.reshape(n_points, 1, 32, 32, 3)\n",
    "\n",
    "model_args = Namespace()\n",
    "n_test_ex, one, model_args.height, model_args.width, model_args.n_col = x_test.shape\n",
    "model_args.n_in, model_args.n_out = model_args.height * model_args.width * model_args.n_col, y_test.shape[1]\n",
    "model_args.n_hs = []\n",
    "model_args.seed = 1\n",
    "model_args.nn_type = \"cnn\"\n",
    "model_args.dataset = \"cifar10\"\n",
    "\n",
    "robustness_curve_data = dict()\n",
    "\n",
    "for training_method in [\"ST\", \"MMR+AT_l_inf\", \"MMR+AT_l_2\", \"KW_l_inf\", \"KW_l_2\", \"AT_l_inf\", \"AT_l_2\", \"MMRUNIV\"]:\n",
    "\n",
    "    robustness_curve_data[training_method] = load_from_json(\"rob_curve_data_{}_n_points={}\".format(training_method, n_points))\n",
    "\n",
    "    if not robustness_curve_data[training_method]:\n",
    "        \n",
    "        sess = tf.InteractiveSession()\n",
    "        model, _input, _logits, _ = load_model(sess, model_args, training_method_to_model_path[training_method])\n",
    "        \n",
    "        f_model = foolbox.models.TensorFlowModel(_input, _logits, (0,1))\n",
    "        \n",
    "        args = Namespace()\n",
    "\n",
    "        args.inputs = x_test\n",
    "        args.labels = y_test\n",
    "        args.f_model = f_model\n",
    "        args.norms = [\"inf\"]\n",
    "        args.save = False\n",
    "        args.plot = False\n",
    "\n",
    "        robustness_curve_data[training_method] = generate_curve_data(args)\n",
    "\n",
    "        save_to_json(robustness_curve_data[training_method], \"rob_curve_data_{}_n_points={}\".format(training_method, n_points))\n",
    "        \n",
    "        tf.reset_default_graph()\n",
    "        sess.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Print Table Data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_nearest(array, value):\n",
    "    array = np.asarray(array)\n",
    "    idx = (np.abs(array - value)).argmin()\n",
    "    return idx, array[idx]\n",
    "\n",
    "for training_method in [\"ST\", \"AT_l_inf\", \"KW_l_inf\", \"MMR+AT_l_inf\", \"MMRUNIV\"]:\n",
    "    for threshold in [1/255, 4/255, 8/255]:\n",
    "        nearest_index, nearest_value = find_nearest(robustness_curve_data[training_method][\"inf\"][\"x\"], threshold)\n",
    "        print(\"dfun=l_infty eps={:.4f} method={} robust error={:.2f}\".format(threshold, training_method, robustness_curve_data[training_method][\"inf\"][\"y\"][nearest_index]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
